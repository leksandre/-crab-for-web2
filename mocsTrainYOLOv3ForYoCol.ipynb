{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leksandre/-crab-for-web2ipr_book_shop/blob/main/mocsTrainYOLOv3ForYoCol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hLmHrgkdgLA"
      },
      "source": [
        "# Training YOLOv3 From Scratch with Darknet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-OPjabVazql",
        "outputId": "6c183f37-9071-4525-8fd4-ce1c9d662848"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "t9l8GKZkbSvv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cd /content/drive/MyDrive/mocs_dataset/"
      ],
      "metadata": {
        "id": "7zPw3YhYbdfb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isoAIh-QbU-M",
        "outputId": "5ca30d1b-3cf3-4b0d-b58e-58660f3ce6ae"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbackup\u001b[0m/   \u001b[01;34mdata\u001b[0m/      libdarknet.a    LICENSE.fuck  LICENSE.meta  Makefile  README.md  \u001b[01;34msrc\u001b[0m/\n",
            "\u001b[01;34mcfg\u001b[0m/      \u001b[01;34mexamples\u001b[0m/  \u001b[01;32mlibdarknet.so\u001b[0m*  LICENSE.gen   LICENSE.mit   \u001b[01;34mobj\u001b[0m/      \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;32mdarknet\u001b[0m*  \u001b[01;34minclude\u001b[0m/   LICENSE         LICENSE.gpl   LICENSE.v1    \u001b[01;34mpython\u001b[0m/   \u001b[01;34mscripts\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao6Ajv2kb0Un",
        "outputId": "de8ce574-df6f-4af6-cd4d-28cdbf9b9dcd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YoCol/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unrar x -Y \"/content/drive/MyDrive/mocs_dataset/instances_test.rar\" \"/content/instances_test/\""
      ],
      "metadata": {
        "id": "wbOkp5BZYalU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unrar x -Y \"/content/drive/MyDrive/mocs_dataset/instances_train.rar\" \"/content/instances_train/\""
      ],
      "metadata": {
        "id": "xx-a3sixYcAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unrar x -Y \"/content/drive/MyDrive/mocs_dataset/instances_test.rar\" \"/content/drive/MyDrive/mocs_dataset/instances_test/\""
      ],
      "metadata": {
        "id": "UEOpp3-4ljgE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unrar x -Y \"/content/drive/MyDrive/mocs_dataset/instances_train.rar\" \"/content/drive/MyDrive/mocs_dataset/instances_train/\""
      ],
      "metadata": {
        "id": "Z74cjrbNljIF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#not completed\n",
        "# !unrar x -Y \"/content/drive/MyDrive/mocs_dataset/instances_val.rar\" \"/content/drive/MyDrive/mocs_dataset/instances_val/\""
      ],
      "metadata": {
        "id": "nAdxS4LWko9e"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYxndAs_dYid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6503124-c2c9-4bbd-8216-0bec9b9e5c4c"
      },
      "source": [
        "!git clone https://github.com/Oskop/YoCol"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YoCol'...\n",
            "remote: Enumerating objects: 1172, done.\u001b[K\n",
            "remote: Total 1172 (delta 0), reused 0 (delta 0), pack-reused 1172\u001b[K\n",
            "Receiving objects: 100% (1172/1172), 11.32 MiB | 24.05 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-1xgy1QfYZw"
      },
      "source": [
        "## Setup Environment For Darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkUV_R7A6NgM"
      },
      "source": [
        "Since Google Colab has pre-installed CUDA 10, then we can skip CUDA configuration and go to next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3bQuj4vemVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a51d11-d83c-4b41-ef02-0c5a3796f89a"
      },
      "source": [
        "#Installing compilers\n",
        "!apt install gcc-5 g++-5 -y"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package g++-5 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  gcc-10-test-results gcc-9-test-results gcc-12-test-results gcc-11-test-results\n",
            "\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package gcc-5\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mPackage 'g++-5' has no installation candidate\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3QDRKB0g9W3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c39467-1e91-4c82-c995-16091940e0a6"
      },
      "source": [
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link '/usr/local/cuda/bin/gcc': File exists\n",
            "ln: failed to create symbolic link '/usr/local/cuda/bin/g++': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EfBYVeXGG4CI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msnPo5t-hEo1"
      },
      "source": [
        "#Changing the variables to include OpenCV and GPU in the Makefile\n",
        "! cd /content/YoCol/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "#!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile if you want to use cudnn"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd1BU4QfhMKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f23d67-bd14-4ef9-a44c-52757433903a"
      },
      "source": [
        "# Apparently we need to install this so that OpenCV can work without any issues\n",
        "# when we are making the file\n",
        "!apt-get install libopencv-dev"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopencv-dev is already the newest version (4.5.4+dfsg-9ubuntu4+jammy0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# babakasd#break here"
      ],
      "metadata": {
        "id": "1qy6KWg24dK2"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mibkWf-0h4BD"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RbpEdd8uJ5W"
      },
      "source": [
        "###Download and Extract COCO Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Anx1Bn0nu7p"
      },
      "source": [
        "Include COCO dataset that handled with get_coco_dataset.sh script so we don't need to convert label format from COCO format to YOLOv3 format. This step is an optional so you can skip if you think there's no need to including COCO dataset into training process. But if you not include COCO dataset, then you must use yolov3.weights from official site to continue the training process because the number of classes for this config is including COCO 80 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKiDc5IqqUC-"
      },
      "source": [
        "# %cd /content/YoCol/darknet\n",
        "# !sh scripts/get_coco_dataset.sh"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J793KmInh2gP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90eaed7-d685-4899-9cac-e6b16639559c"
      },
      "source": [
        "%cd /content/YoCol/darknet/coco\n",
        "!paste <(awk \"{pri!nt \\\"$PWD\\\"}\" <5k.part) 5k.part | tr -d '\\t' > 5k.txt\n",
        "!paste <(awk \"{print \\\"$PWD\\\"}\" <trainvalno5k.part) trainvalno5k.part | tr -d '\\t' > trainvalno5k.txt\n",
        "%cd /content"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/YoCol/darknet/coco'\n",
            "/content/YoCol/darknet\n",
            "paste: 5k.part: No such file or directory\n",
            "/bin/bash: line 1: 5k.part: No such file or directory\n",
            "paste: trainvalno5k.part: No such file or directory\n",
            "/bin/bash: line 1: trainvalno5k.part: No such file or directory\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4jRPnT9kfE7"
      },
      "source": [
        "### Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvnc7yMSSxdg"
      },
      "source": [
        "We load the MATLAB annotations file first, then adding to a new dictionary that store both the Standford labels and COCO labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rREnElU5kqGk"
      },
      "source": [
        "# load labels that i've already annotate to train and test\n",
        "# standford images with YOLOv3 (contain 80 classes of COCO classes,\n",
        "# 196 classes from Sandford classes are not include in this data.json file)\n",
        "import json\n",
        "cars_make_model_label = open('/content/drive/MyDrive/mocs_dataset/image_info_test.json', 'r')\n",
        "standford_label = json.load(cars_make_model_label)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(standford_label['categories'])\n",
        "all_label = {}\n",
        "all_names = []\n",
        "all_images = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bxBfw71yT4l",
        "outputId": "4ae120e9-17f6-40c3-dca8-df53669ac10b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'supercategory': 'Construction', 'id': 1, 'name': 'Worker'}, {'supercategory': 'Construction', 'id': 2, 'name': 'Static crane'}, {'supercategory': 'Construction', 'id': 3, 'name': 'Hanging head'}, {'supercategory': 'Construction', 'id': 4, 'name': 'Crane'}, {'supercategory': 'Construction', 'id': 5, 'name': 'Roller'}, {'supercategory': 'Construction', 'id': 6, 'name': 'Bulldozer'}, {'supercategory': 'Construction', 'id': 7, 'name': 'Excavator'}, {'supercategory': 'Construction', 'id': 8, 'name': 'Truck'}, {'supercategory': 'Construction', 'id': 9, 'name': 'Loader'}, {'supercategory': 'Construction', 'id': 10, 'name': 'Pump truck'}, {'supercategory': 'Construction', 'id': 11, 'name': 'Concrete mixer'}, {'supercategory': 'Construction', 'id': 12, 'name': 'Pile driving'}, {'supercategory': 'Construction', 'id': 13, 'name': 'Other vehicle'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X39KEF3hx8lo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiKWCM45TXar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdeaaee1-6988-4939-97d6-ca0ff643d723"
      },
      "source": [
        "#process image_info_test.json categories\n",
        "# Initialize dictionary that will contain all label from both labels data\n",
        "for categories in standford_label['categories']:\n",
        "  print(categories['name'])\n",
        "  all_names.append(categories['name'])\n",
        "  all_label[categories['name']] = []\n",
        "print(all_label)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker\n",
            "Static crane\n",
            "Hanging head\n",
            "Crane\n",
            "Roller\n",
            "Bulldozer\n",
            "Excavator\n",
            "Truck\n",
            "Loader\n",
            "Pump truck\n",
            "Concrete mixer\n",
            "Pile driving\n",
            "Other vehicle\n",
            "{'Worker': [], 'Static crane': [], 'Hanging head': [], 'Crane': [], 'Roller': [], 'Bulldozer': [], 'Excavator': [], 'Truck': [], 'Loader': [], 'Pump truck': [], 'Concrete mixer': [], 'Pile driving': [], 'Other vehicle': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#process image_info_test.json images\n",
        "for images in standford_label['images']:\n",
        "  all_images[images['file_name']] = images\n",
        "print(len(all_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VI9Wq9k7VVP",
        "outputId": "03eedba6-f32d-469e-8328-fe630f17c57f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import scipy.io as scio\n",
        "import os\n",
        "import cv2\n",
        "# matlab_train_label = scio.loadmat('devkit/cars_train_annos.mat')\n",
        "# matlab_test_label = scio.loadmat('devkit/cars_test_annos_withlabels.mat')\n",
        "YOLO_CLASS = 13\n",
        "TRAIN_IMAGE_PATH = '/content/drive/MyDrive/mocs_dataset/instances_train/'\n",
        "TEST_IMAGE_PATH = '/content/drive/MyDrive/mocs_dataset/instances_train/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nONS14jUy4Me",
        "outputId": "4ce9b429-ccaf-491a-d9d4-54701ce4d1e9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-VBmD_-VmBO"
      },
      "source": [
        "# Changing test label file name from \"file_names_test\" list to adjust\n",
        "# the key format from data.json\n",
        "# for name in file_names_test:\n",
        "#   for file_name in name:\n",
        "#     if (int(file_name.split('.')[0])+8144) < 10000:\n",
        "#       new_name = '0' + str(int(file_name.split('.')[0]) + 8144) + '.jpg'\n",
        "#       name[0] = new_name\n",
        "#       os.rename(TEST_IMAGE_PATH + file_name, TEST_IMAGE_PATH + new_name)\n",
        "#     else:\n",
        "#       new_name = str(int(file_name.split('.')[0]) + 8144) + '.jpg'\n",
        "#       name[0] = new_name\n",
        "#       os.rename(TEST_IMAGE_PATH + file_name, TEST_IMAGE_PATH + new_name)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_make_model_label = open('/content/drive/MyDrive/mocs_dataset/instances_train.json', 'r')\n",
        "train_label = json.load(cars_make_model_label)"
      ],
      "metadata": {
        "id": "Mu7vIbOB7JJX"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_make_model_label = open('/content/drive/MyDrive/mocs_dataset/instances_val.json', 'r')\n",
        "val_label = json.load(cars_make_model_label)"
      ],
      "metadata": {
        "id": "NLRFdu-DV9CN"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C-2105C_V7S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_make_model_label = open('/content/drive/MyDrive/mocs_dataset/image_info_test.json', 'r')\n",
        "test_label = json.load(cars_make_model_label)"
      ],
      "metadata": {
        "id": "p1kZiJZq8UL0"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "pSqxjjM3KQxf"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def procStupidMocsYoloStruk(struck, prevListOfDicts = []):\n",
        "  all_images = {}\n",
        "  annotations = struck['annotations']\n",
        "  images = struck['images']\n",
        "  categories = struck['categories']\n",
        "  for image in images:\n",
        "    file_name = image['file_name']\n",
        "    file_id = image['id']\n",
        "    all_images[file_name] = []\n",
        "    image = cv2.imread(TRAIN_IMAGE_PATH + file_name)\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    filtered_list = list(filter(lambda x: x[\"image_id\"] == file_id, annotations))\n",
        "    for annotation in filtered_list:\n",
        "      if 1:\n",
        "      # if image.shape[1] >= 300:\n",
        "          filtered_cats = list(filter(lambda x: x[\"id\"] == annotation['category_id'], categories))\n",
        "          filtered_cat = filtered_cat[0]\n",
        "          obj_class = str(filtered_cat['name'])\n",
        "          x1 = float(annotation['bbox'][0])\n",
        "          x2 = float(annotation['bbox'][1])\n",
        "          y1 = float(annotation['bbox'][2])\n",
        "          y2 = float(annotation['bbox'][3])\n",
        "\n",
        "    # if bbox[0] < 0:\n",
        "    #   left = 0\n",
        "    # else:\n",
        "    #   left = bbox[0]\n",
        "    # if bbox[1] < 0:\n",
        "    #   top = 0\n",
        "    # else:\n",
        "    #   top = bbox[1]\n",
        "    # if bbox[2] < 0:\n",
        "    #   right = 1\n",
        "    # else:\n",
        "    #   right = bbox[2]\n",
        "    # if bbox[3] < 0:\n",
        "    #   bottom = 1\n",
        "    # else:\n",
        "    #   bottom = bbox[3]\n",
        "\n",
        "          x_center = str(((x2-x1) / 2) / width)\n",
        "          y_center = str(((y2-y1) / 2) / height)\n",
        "          obj_width = str((x2-x1) / width)\n",
        "          obj_height = str((y2-y1) / height)\n",
        "          all_images[file_name].append(obj_class + ' ' + x_center + ' ' + y_center +\n",
        "                                      ' ' + obj_width + ' ' + obj_height)\n",
        "\n",
        "  prevListOfDicts[0] = all_images.update(prevListOfDicts[0] )\n",
        "  return all_images"
      ],
      "metadata": {
        "id": "BnUrBuUI-Xcv"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aCeGw_R2SCSz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DAZ_xme67Zs"
      },
      "source": [
        "Then we move COCO Training and Validation images and its labels into Standford Images Directory. Labels data are moved to image directory because darknet will detect our label in same directory as images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01S3xkKoz73X"
      },
      "source": [
        "# Moving COCO Images into Standford Images Directory\n",
        "# !mv /content/YoCol/darknet/coco/images/train2014/* /content/cars_train\n",
        "# !mv /content/YoCol/darknet/coco/images/val2014/* /content/casr_test"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti1b8NM35QF2"
      },
      "source": [
        "# # Moving COCO Labels into Standford Images Directory\n",
        "# !mv /content/YoCol/darknet/coco/labels/train2014/* /content/cars_train\n",
        "# !mv /content/YoCol/darknet/coco/labels/val2014/* /content/cars_test"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay5moePX82up"
      },
      "source": [
        "Darknet need to a list file of image file path that will be passes to darknet for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGpShQi31BB-"
      },
      "source": [
        "# Make list file of train and test image file path\n",
        "train_images_list = os.listdir(TRAIN_IMAGE_PATH)\n",
        "test_images_list = os.listdir(TEST_IMAGE_PATH)\n",
        "train_list_file = open('/content/train_list.txt', 'w')\n",
        "test_list_file = open('/content/test_list.txt', 'w')\n",
        "names_file = open('/content/names.txt', 'w')\n",
        "for img_name in train_images_list:\n",
        "  train_list_file.write(TRAIN_IMAGE_PATH + img_name + '\\n')\n",
        "for img_name2 in test_images_list:\n",
        "  test_list_file.write(TEST_IMAGE_PATH + img_name2 + '\\n')\n",
        "for nameClass in all_names:\n",
        "  names_file.write(nameClass + '\\n')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfVUq_Qo3yZJ"
      },
      "source": [
        "\n",
        "# why they create huge txt files?\n",
        "# Then we start labelling Standford Dataset based on labels data that stored in\n",
        "# \"all_label\" dictionary\n",
        "\n",
        "# for name in all_label:\n",
        "#   if int(name[:-4]) < 8145 :\n",
        "#     label_file = open(TRAIN_IMAGE_PATH + name[:-4] + '.txt', 'w')\n",
        "#   else:\n",
        "#     label_file = open(TEST_IMAGE_PATH + name[:-4] + '.txt', 'w')\n",
        "#   for label in all_label[name]:\n",
        "#     label_file.write(label + '\\n')"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waq6FzMx5PqW"
      },
      "source": [
        "##Setting before Training for Yolov3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhFfVndw-BnP"
      },
      "source": [
        "Darknet need some configuration file befor training YOLO model that had \".data\" extension. This file contains some configuration such as where darknet must take list file of training and validation, classes names that will use for YOLO, and path to store .weights file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/bk/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrJSeeIQUMfH",
        "outputId": "93d8ff2b-0d00-47ad-940a-25bda521c3d5"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/bk/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhmIIvF5UrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25910e7-22c3-4011-83f2-d30e0798ee53"
      },
      "source": [
        "!mkdir /content/weight\n",
        "dat = \"\"\"classes = 13\n",
        "train = /content/train_list.txt\n",
        "valid = /content/test_list.txt\n",
        "names = /content/names.txt\n",
        "backup = /content/bk/\"\"\"\n",
        "with open('/content/darknet.data','w') as dark:\n",
        "  dark.write(dat)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/weight’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-2SGhL_xEJ"
      },
      "source": [
        "####Compile Darknet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaL6rmY196AA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f585a4-4263-49b2-e09f-612f7714dbb5"
      },
      "source": [
        "%cd /content/YoCol/darknet\n",
        "!make\n",
        "#Check if darknet is installed properly\n",
        "!./darknet detector help"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YoCol/darknet\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/gemm.c -o obj/gemm.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktime_gpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:232:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcudaThreadSynchronize\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  232 |         \u001b[01;35m\u001b[KcudaThreadSynchronize\u001b[m\u001b[K();\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/utils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gemm.c:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:1069:57:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 1069 | extern __CUDA_DEPRECATED __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaThreadSynchronize\u001b[m\u001b[K(void);\n",
            "      |                                                         \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/utils.c -o obj/utils.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/cuda.c -o obj/cuda.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/deconvolutional_layer.c -o obj/deconvolutional_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/list.c -o obj/list.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/image.c -o obj/image.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/activations.c -o obj/activations.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/im2col.c -o obj/im2col.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/col2im.c -o obj/col2im.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/blas.c -o obj/blas.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/crop_layer.c -o obj/crop_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/data.c -o obj/data.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/matrix.c -o obj/matrix.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/network.c -o obj/network.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/connected_layer.c -o obj/connected_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/cost_layer.c -o obj/cost_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/parser.c -o obj/parser.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/option_list.c -o obj/option_list.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/detection_layer.c -o obj/detection_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/route_layer.c -o obj/route_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/box.c -o obj/box.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/layer.c -o obj/layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/local_layer.c -o obj/local_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/logistic_layer.c -o obj/logistic_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/activation_layer.c -o obj/activation_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/gru_layer.c -o obj/gru_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/demo.c -o obj/demo.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/region_layer.c -o obj/region_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/tree.c -o obj/tree.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/l2norm_layer.c -o obj/l2norm_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "gcc -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/iseg_layer.c -o obj/iseg_layer.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "g++ -Iinclude/ -Isrc/ -DOPENCV `pkg-config --cflags opencv`  -DGPU -I/usr/local/cuda/include/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -DOPENCV -DGPU -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "Package opencv was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `opencv.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'opencv' found\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:5:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kopencv2/opencv.hpp: No such file or directory\n",
            "    5 | #include \u001b[01;31m\u001b[K\"opencv2/opencv.hpp\"\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "make: *** [Makefile:86: obj/image_opencv.o] Error 1\n",
            "usage: ./darknet detector [train/test/valid] [cfg] [weights (optional)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBPAxHeI7B_f"
      },
      "source": [
        "##Start Training Yolov3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtp73noL5zsJ"
      },
      "source": [
        "The training is start from scratch because we include both dataset and want to not only detect Standford Car classes name but also 80 COCO classes name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac9O1wgu8_wM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf85ea4-31ab-496b-b5da-e04cf06d90b9"
      },
      "source": [
        "%cd /content/YoCol/darknet/\n",
        "!./darknet detector train /content/darknet.data cfg/yolov3.cfg &> /dev/null"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YoCol/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/darknet.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjx0ngCNdh-P",
        "outputId": "4033676e-aa34-46ef-eebf-5fe0a3bedd5b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes = 13\n",
            "train = /content/train_list.txt\n",
            "valid = /content/test_list.txt\n",
            "names = /content/names.txt\n",
            "backup = /content/bk/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNPxypDfdk-F",
        "outputId": "251f8e20-dff0-4dbb-8084-cd74b1ca921a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker\n",
            "Static crane\n",
            "Hanging head\n",
            "Crane\n",
            "Roller\n",
            "Bulldozer\n",
            "Excavator\n",
            "Truck\n",
            "Loader\n",
            "Pump truck\n",
            "Concrete mixer\n",
            "Pile driving\n",
            "Other vehicle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head 10 /content/train_list.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lcu7sB3drBn",
        "outputId": "09a4a03f-d811-4efa-c69b-b6cd412439c6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open '10' for reading: No such file or directory\n",
            "==> /content/train_list.txt <==\n",
            "/content/drive/MyDrive/mocs_dataset/instances_train/instances_train\n",
            "/content/drive/MyDrive/mocs_dataset/instances_train/Readme.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head 10 /content/test_list.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp4uH640d4TP",
        "outputId": "2c5925e5-3660-4621-b5bf-e94d08472121"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open '10' for reading: No such file or directory\n",
            "==> /content/test_list.txt <==\n",
            "/content/drive/MyDrive/mocs_dataset/instances_train/instances_train\n",
            "/content/drive/MyDrive/mocs_dataset/instances_train/Readme.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat cfg/yolov3.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AumDFr7XdzSH",
        "outputId": "38f53141-1e7e-4d05-9df4-b4f254aaa099"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[net]\n",
            "# Testing\n",
            "# batch=1\n",
            "# subdivisions=1\n",
            "# Training\n",
            "batch=64\n",
            "subdivisions=16\n",
            "width=416\n",
            "height=416\n",
            "channels=3\n",
            "momentum=0.9\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "learning_rate=0.001\n",
            "burn_in=1000\n",
            "max_batches = 552000\n",
            "policy=steps\n",
            "steps=400000,450000\n",
            "scales=.1,.1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "######################\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=843\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 6,7,8\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=276\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 61\n",
            "\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=843\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=276\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "\n",
            "\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 36\n",
            "\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=843\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 0,1,2\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=276\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}