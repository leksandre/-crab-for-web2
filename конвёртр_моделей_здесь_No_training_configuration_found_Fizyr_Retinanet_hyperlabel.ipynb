{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leksandre/-crab-for-web2ipr_book_shop/blob/main/%D0%BA%D0%BE%D0%BD%D0%B2%D1%91%D1%80%D1%82%D1%80_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9_%D0%B7%D0%B4%D0%B5%D1%81%D1%8C_No_training_configuration_found_Fizyr_Retinanet_hyperlabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzgPkIP1irG3"
      },
      "source": [
        "# Object Detection in Google Colab with Fizyr Retinanet\n",
        "\n",
        "Jupyter notebook providing steps to train a Keras/Tensorflow model for object detection with custom dataset.\n",
        "\n",
        "It runs in Google Colab using [Fizyr implementation](https://github.com/fizyr/keras-retinanet) of RetinaNet in Keras.\n",
        "\n",
        "Requirements are only dataset images and annotations file made in [LabelImg](https://github.com/tzutalin/labelImg).\n",
        "\n",
        "Colab Runtime type: Python3, GPU enabled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6D_Wz3h5ILS"
      },
      "source": [
        "# Environment Setup\n",
        "Download and install in Colab required packages and import libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlBbB77Siz4j",
        "outputId": "03df27f6-cb36-4d73-c0dc-b2c89e5e896c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras 2.4 and tensorflow 2.3.0"
      ],
      "metadata": {
        "id": "1ErTCImbV1Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PdMj4Tn3tgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0772713-d632-4db5-e977-9b9f9b1f2506"
      },
      "source": [
        "!git clone https://github.com/fizyr/keras-retinanet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 6224, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 6224 (delta 6), reused 9 (delta 2), pack-reused 6205\u001b[K\n",
            "Receiving objects: 100% (6224/6224), 13.48 MiB | 20.79 MiB/s, done.\n",
            "Resolving deltas: 100% (4207/4207), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPLMzdXZ5BGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a537acf5-cead-4b67-babb-2d784338bd22"
      },
      "source": [
        "%cd keras-retinanet/\n",
        "\n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-retinanet\n",
            "Processing /content/keras-retinanet\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-resnet==0.2.0 (from keras-retinanet==1.0.0)\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (3.0.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (9.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (from keras-retinanet==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.10/dist-packages (from keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2->keras-retinanet==1.0.0) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2->keras-retinanet==1.0.0) (4.10.0)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp310-cp310-linux_x86_64.whl size=208086 sha256=61f913399d29a10fee2823621a27408ff2c6baa2a928e63e8377824d5f7a69c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/a8/71/bccf2f8331abdd2183df34261c5faea07ce65324a12c97af2e\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20456 sha256=9507fde68a30a2a2bcdf578f87cf28005e2ad5bceb191c39a0c67351c05bd81a\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/af/88/a668b279c5eadbe55dcaf6207f09059135166cefb09088bacc\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "Successfully installed keras-resnet-0.2.0 keras-retinanet-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWspmGibv2qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e279424-f229-4236-a5a8-ef04d407b32e"
      },
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-cpython-310/keras_retinanet/utils/compute_overlap.cpython-310-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9y6KaHwJhny",
        "outputId": "28fb2f88-8cd5-43f9-992e-48c12c50200a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine-rl, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D-lO9LoHPZI",
        "outputId": "39d0ba61-a3b7-43f8-c37e-adc5cc43f0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 2.15.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: keras-resnet, tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UI7XYyxyJcX"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import urllib\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiIEhwOx8Box"
      },
      "source": [
        "# Making Dataset\n",
        "\n",
        "We will be using HyperLabel to create our dataset. You can watch the following tutorial video about how to use HyperLabel and tag images with it.\n",
        "\n",
        "https://www.youtube.com/embed/R56Ck3tElIs\n",
        "\n",
        "Once all of your images are tagged, its time to export the labels and data in Pascal VOC format. Goto the `review` tab/section and click on the export button. From the export menu, choose `Object Detection` and select Pascal VOC and click on export. It will take some time to export the data, once exported you should be able to see multiple folders, but we are interested in two i.e., `Annotations` and `JPEGImages` folder.\n",
        "\n",
        "Now created a new folder, name it `dataset`. Copy all the contents of `Annotations` folder and `JPEGImages` folder inside `dataset` folder and then create a zip archive of this folder.\n",
        "\n",
        "Upload this zip archive to your Google drive and get the ID. To locate the File ID, right click on the name of the file, choose the Get Shareable Link option, and turn on Link Sharing if needed (you can turn it off later). You will see the link with a combination of numbers and letters at the end, and what you see after id =   is the File ID.\n",
        "\n",
        "https://drive.google.com/open?id=***ThisIsFileID***\n",
        "\n",
        "If your file is already open in a browser, you can obtain File ID from its link:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/***ThisIsFileID***/edit#gid=123456789"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MchXOV8bQmxC"
      },
      "source": [
        "DATASET_DRIVEID = '1E0jDQoud1AuUFB2D5EyHNrqNz20borOr'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErDsqPbi879W"
      },
      "source": [
        "DATASET_DIR = 'dataset'\n",
        "ANNOTATIONS_FILE = 'annotations.csv'\n",
        "CLASSES_FILE = 'classes.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmsR37T7UvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2330760-8c8b-4d3a-f6dc-87add321e089"
      },
      "source": [
        "drive_url = 'https://drive.google.com/uc?export=download&id=' + DATASET_DRIVEID\n",
        "file_name = DATASET_DRIVEID + '.zip'\n",
        "\n",
        "urllib.request.urlretrieve(drive_url, file_name)\n",
        "print('Download completed!')\n",
        "\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "  zip_ref.extractall(DATASET_DIR)\n",
        "os.remove(file_name)\n",
        "\n",
        "print('Extract completed!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Extract completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpfG9bqY8XzN"
      },
      "source": [
        "annotations = []\n",
        "classes = set([])\n",
        "\n",
        "for xml_file in [f for f in os.listdir(DATASET_DIR) if f.endswith(\".xml\")]:\n",
        "  tree = ET.parse(os.path.join(DATASET_DIR, xml_file))\n",
        "  root = tree.getroot()\n",
        "\n",
        "  file_name = None\n",
        "\n",
        "  for elem in root:\n",
        "    if elem.tag == 'filename':\n",
        "      file_name = os.path.join(DATASET_DIR, elem.text)\n",
        "\n",
        "    if elem.tag == 'object':\n",
        "      obj_name = None\n",
        "      coords = []\n",
        "      for subelem in elem:\n",
        "        if subelem.tag == 'name':\n",
        "          obj_name = subelem.text\n",
        "        if subelem.tag == 'bndbox':\n",
        "          xmin = \"\"\n",
        "          xmax = \"\"\n",
        "          ymin = \"\"\n",
        "          ymax = \"\"\n",
        "          for subsubelem in subelem:\n",
        "            f = float(subsubelem.text)\n",
        "            i = int(f)\n",
        "            if subsubelem.tag == \"xmin\":\n",
        "              xmin = str(i)\n",
        "            if subsubelem.tag == \"xmax\":\n",
        "              xmax = str(i)\n",
        "            if subsubelem.tag == \"ymin\":\n",
        "              ymin = str(i)\n",
        "            if subsubelem.tag == \"ymax\":\n",
        "              ymax = str(i)\n",
        "\n",
        "          coords.append(xmin)\n",
        "          coords.append(ymin)\n",
        "          coords.append(xmax)\n",
        "          coords.append(ymax)\n",
        "\n",
        "      item = [file_name] + coords + [obj_name]\n",
        "      annotations.append(item)\n",
        "      classes.add(obj_name)\n",
        "\n",
        "with open(ANNOTATIONS_FILE, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerows(annotations)\n",
        "\n",
        "with open(CLASSES_FILE, 'w') as f:\n",
        "  for i, line in enumerate(classes):\n",
        "    f.write('{},{}\\n'.format(line,i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGtn3JW6Mig8"
      },
      "source": [
        "# Training Model\n",
        "\n",
        "Download pretrained model and run training.\n",
        "\n",
        "In the next cell choose one option:\n",
        "\n",
        "1.   download Fizyr Resnet50 pretrained model\n",
        "2.   download your custom pretrained model, to continue previous training epochs\n",
        "\n",
        "In the last cell optionally export trained model to Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0"
      ],
      "metadata": {
        "id": "SWn3DP7AM7ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5\n",
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\n",
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5\n",
        "!wget -O /content/resnet50_coco_best_v2.1.0.h5 https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7tDH_iCImPa",
        "outputId": "dfe7423e-d848-4aa2-ab8c-246b61e7c65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-01 11:20:29--  https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/e7ab678c-6146-11e8-85cc-26bc1cd06ab0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112029Z&X-Amz-Expires=300&X-Amz-Signature=3262cf7840209ceb9ffab14e8a916840e22a298b460e9c2322b1981cd68a2c67&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.0.1.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-01 11:20:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/e7ab678c-6146-11e8-85cc-26bc1cd06ab0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112029Z&X-Amz-Expires=300&X-Amz-Signature=3262cf7840209ceb9ffab14e8a916840e22a298b460e9c2322b1981cd68a2c67&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.0.1.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152661008 (146M) [application/octet-stream]\n",
            "Saving to: ‘resnet50_coco_best_v2.0.1.h5’\n",
            "\n",
            "resnet50_coco_best_ 100%[===================>] 145.59M  72.5MB/s    in 2.0s    \n",
            "\n",
            "2024-04-01 11:20:32 (72.5 MB/s) - ‘resnet50_coco_best_v2.0.1.h5’ saved [152661008/152661008]\n",
            "\n",
            "--2024-04-01 11:20:32--  https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/1b8496e8-86fc-11e8-895f-fefe61ebb499?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112032Z&X-Amz-Expires=300&X-Amz-Signature=abfe77116c8355bef142d8108fdeac5a5de84e7f145567c5dd7ba6675b5ad3a6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolo.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-01 11:20:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/1b8496e8-86fc-11e8-895f-fefe61ebb499?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112032Z&X-Amz-Expires=300&X-Amz-Signature=abfe77116c8355bef142d8108fdeac5a5de84e7f145567c5dd7ba6675b5ad3a6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolo.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248686624 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolo.h5’\n",
            "\n",
            "yolo.h5             100%[===================>] 237.17M  70.1MB/s    in 3.6s    \n",
            "\n",
            "2024-04-01 11:20:36 (65.5 MB/s) - ‘yolo.h5’ saved [248686624/248686624]\n",
            "\n",
            "--2024-04-01 11:20:36--  https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/7cf559e6-86fa-11e8-81e8-1e959be261a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112037Z&X-Amz-Expires=300&X-Amz-Signature=18805b9874f0b0a42ca1301a4f36285bbdb691b7ba2296b033c556a535988fe2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolo-tiny.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-01 11:20:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/125932201/7cf559e6-86fa-11e8-81e8-1e959be261a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112037Z&X-Amz-Expires=300&X-Amz-Signature=18805b9874f0b0a42ca1301a4f36285bbdb691b7ba2296b033c556a535988fe2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dyolo-tiny.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35555784 (34M) [application/octet-stream]\n",
            "Saving to: ‘yolo-tiny.h5’\n",
            "\n",
            "yolo-tiny.h5        100%[===================>]  33.91M  71.9MB/s    in 0.5s    \n",
            "\n",
            "2024-04-01 11:20:38 (71.9 MB/s) - ‘yolo-tiny.h5’ saved [35555784/35555784]\n",
            "\n",
            "--2024-04-01 11:20:38--  https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112038Z&X-Amz-Expires=300&X-Amz-Signature=7ca37bd3b228bb28380a8b25f31a5bbdf7c6acd9bad4e1cd2c7a7142805f4b28&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-01 11:20:38--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240401T112038Z&X-Amz-Expires=300&X-Amz-Signature=7ca37bd3b228bb28380a8b25f31a5bbdf7c6acd9bad4e1cd2c7a7142805f4b28&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152662144 (146M) [application/octet-stream]\n",
            "Saving to: ‘/content/resnet50_coco_best_v2.1.0.h5’\n",
            "\n",
            "/content/resnet50_c 100%[===================>] 145.59M   145MB/s    in 1.0s    \n",
            "\n",
            "2024-04-01 11:20:39 (145 MB/s) - ‘/content/resnet50_coco_best_v2.1.0.h5’ saved [152662144/152662144]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKcCJNfZ1YVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXQzV1yhz3jI"
      },
      "source": [
        "# PRETRAINED_MODEL = './snapshots/_pretrained_model.h5'\n",
        "\n",
        "# #### OPTION 1: DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR ####\n",
        "# URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n",
        "# urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n",
        "\n",
        "# #### OPTION 2: DOWNLOAD CUSTOM PRETRAINED MODEL FROM GOOGLE DRIVE. CHANGE DRIVE_MODEL VALUE. USE THIS TO CONTINUE PREVIOUS TRAINING EPOCHS ####\n",
        "# drive.mount('/content/gdrive')\n",
        "# DRIVE_MODEL = '/content/gdrive/My Drive/Colab Notebooks/resnet50_csv_10.h5'\n",
        "# shutil.copy(DRIVE_MODEL, './snapshots/resnet50_csv_10.h5')\n",
        "\n",
        "\n",
        "# print('Downloaded pretrained model to ' + PRETRAINED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bexsEvq_zb6"
      },
      "source": [
        "# !keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 500 --epochs 10 csv annotations.csv classes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgfE5aDQHFz8"
      },
      "source": [
        "# #### OPTIONAL: EXPORT TRAINED MODEL TO DRIVE ####\n",
        "# drive.mount('/content/gdrive')\n",
        "# COLAB_MODEL = './snapshots/resnet50_csv_10.h5'\n",
        "# DRIVE_DIR = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "# shutil.copy(COLAB_MODEL, DRIVE_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1QimaHHh_M0"
      },
      "source": [
        "# Inference\n",
        "Run inference with uploaded image on trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfsj1KOVzTdi"
      },
      "source": [
        "THRES_SCORE = 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyfa8yniJiW"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "import tensorflow\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.Session(config=config)\n",
        "\n",
        "# use this environment flag to change which GPU to use\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the modified tf session as backend in keras\n",
        "# keras.backend.tensorflow_backend.set_session(get_session())\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "K.set_session(sess)\n",
        "# K.set_session(get_session())"
      ],
      "metadata": {
        "id": "ByL00YtkKzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mv ./*.h5 ../"
      ],
      "metadata": {
        "id": "13rLJfjuMzSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lsaht"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEpAeeZYMwAh",
        "outputId": "dc7c75ad-d484-4758-a67d-d60430aa1864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 417M\n",
            "4.0K drwxr-xr-x 10 root root 4.0K Apr  1 11:20 keras_retinanet\n",
            "4.0K drwxr-xr-x  1 root root 4.0K Apr  1 11:20 ..\n",
            "4.0K drwxr-xr-x 12 root root 4.0K Apr  1 11:20 .\n",
            "4.0K -rw-r--r--  1 root root   44 Apr  1 11:20 classes.csv\n",
            "116K -rw-r--r--  1 root root 114K Apr  1 11:20 annotations.csv\n",
            " 72K drwxr-xr-x  2 root root  68K Apr  1 11:20 dataset\n",
            "4.0K drwxr-xr-x  2 root root 4.0K Apr  1 11:19 keras_retinanet.egg-info\n",
            "4.0K drwxr-xr-x  5 root root 4.0K Apr  1 11:19 build\n",
            "4.0K drwxr-xr-x  8 root root 4.0K Apr  1 11:19 .git\n",
            "4.0K drwxr-xr-x  9 root root 4.0K Apr  1 11:19 tests\n",
            "4.0K -rw-r--r--  1 root root  205 Apr  1 11:19 requirements.txt\n",
            "4.0K -rw-r--r--  1 root root  413 Apr  1 11:19 setup.cfg\n",
            "4.0K -rw-r--r--  1 root root 2.4K Apr  1 11:19 setup.py\n",
            "4.0K drwxr-xr-x  2 root root 4.0K Apr  1 11:19 snapshots\n",
            "4.0K drwxr-xr-x  2 root root 4.0K Apr  1 11:19 images\n",
            "4.0K drwxr-xr-x  2 root root 4.0K Apr  1 11:19 examples\n",
            "4.0K -rw-r--r--  1 root root 1.4K Apr  1 11:19 CONTRIBUTORS.md\n",
            "4.0K drwxr-xr-x  3 root root 4.0K Apr  1 11:19 .github\n",
            "4.0K -rw-r--r--  1 root root  273 Apr  1 11:19 .gitignore\n",
            "4.0K -rw-r--r--  1 root root  116 Apr  1 11:19 .gitmodules\n",
            " 12K -rw-r--r--  1 root root  12K Apr  1 11:19 LICENSE\n",
            " 24K -rw-r--r--  1 root root  21K Apr  1 11:19 README.md\n",
            "4.0K -rw-r--r--  1 root root  439 Apr  1 11:19 .travis.yml\n",
            "4.0K -rw-r--r--  1 root root 1.2K Apr  1 11:19 .codecov.yml\n",
            " 34M -rw-r--r--  1 root root  34M Dec  6  2021 yolo-tiny.h5\n",
            "238M -rw-r--r--  1 root root 238M Dec  6  2021 yolo.h5\n",
            "146M -rw-r--r--  1 root root 146M Dec  6  2021 resnet50_coco_best_v2.0.1.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BczjgvRuLtA3",
        "outputId": "11e15468-39e6-4a59-d919-9223c5a46acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-retinanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lsaht /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Una51E4nBfJI",
        "outputId": "be30948c-8b83-4ac4-d83d-b26ed84dfbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 146M\n",
            "4.0K drwxr-xr-x  1 root root 4.0K Apr  1 11:20 .\n",
            "4.0K drwxr-xr-x 12 root root 4.0K Apr  1 11:20 keras-retinanet\n",
            "4.0K drwxr-xr-x  1 root root 4.0K Apr  1 11:07 ..\n",
            "4.0K drwxr-xr-x  1 root root 4.0K Mar 28 23:00 sample_data\n",
            "4.0K drwxr-xr-x  4 root root 4.0K Mar 28 22:59 .config\n",
            "146M -rw-r--r--  1 root root 146M Dec  6  2021 resnet50_coco_best_v2.1.0.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_retinanet.models import retinanet\n",
        "from keras.applications import  mobilenet\n",
        "custom_objects = tensorflow.keras.saving.get_custom_objects()\n"
      ],
      "metadata": {
        "id": "aXoZwMuvK0mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\n",
        "# print(model_path)\n",
        "\n",
        "# model_path = '/content/resnet50_coco_best_v2.1.0_.h5'\n",
        "model_path = '/content/resnet50_coco_03.h5'\n",
        "# model_path = '/content/resnet50_coco_best_v2.0.1.h5'\n",
        "# model_path = '/content/yoloMyv3_120000_weights.h5'"
      ],
      "metadata": {
        "id": "lxv-_co7Qo6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_retinanet.models\n",
        "model = keras_retinanet.models.backbone('resnet50').retinanet(13)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "model.save('/content/resnet50_coco_03_new.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "z1F4jGw4SvGX",
        "outputId": "c28fa7ba-9ef9-44a1-a379-951e095e194b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/content/resnet50_coco_03.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4a3140962246>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_retinanet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_retinanet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretinanet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/resnet50_coco_03_new.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/content/resnet50_coco_03.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(model_path+\"__\", compile=True)\n",
        "# model.save('/content/retinanet_resnet501111.h5')"
      ],
      "metadata": {
        "id": "wsbmWAi5Ta6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load retinanet model\n",
        "# model = models.load_model(model_path, backbone_name='resnet50')\n",
        "model = models.load_model(model_path)\n",
        "# from ..models.densenet import custom_objects\n",
        "#"
      ],
      "metadata": {
        "id": "QfOpf8BiQnQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(model_path, custom_objects=custom_objects)"
      ],
      "metadata": {
        "id": "LGH-4gHMHBuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.convert_model(model)"
      ],
      "metadata": {
        "id": "nNS_RBztUCcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkewNh9UiOs1"
      },
      "source": [
        "\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pandas.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWSHqP1KTHxQ"
      },
      "source": [
        "def img_inference(img_path):\n",
        "  image = read_image_bgr(img_infer)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < THRES_SCORE:\n",
        "          break\n",
        "\n",
        "      color = label_color(label)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "\n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      print(caption)\n",
        "      draw_caption(draw, b, caption)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(draw)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_AoWG4lHFME"
      },
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "img_infer = list(uploaded)[0]\n",
        "\n",
        "print('Running inference on: ' + img_infer)\n",
        "img_inference(img_infer)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}